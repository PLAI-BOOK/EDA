{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-14T09:27:32.668158Z",
     "start_time": "2025-01-14T09:27:31.500653Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "first_100_games_file = 'first_100_games.csv'\n",
    "filtered_merged_events_file = 'filtered_merged_events.csv'\n",
    "\n",
    "# Step 1: Read the CSV files into DataFrames\n",
    "print(f\"Reading '{first_100_games_file}'...\")\n",
    "first_100_games_data = pd.read_csv(first_100_games_file)\n",
    "print(f\"'{first_100_games_file}' loaded with {len(first_100_games_data)} rows.\")\n",
    "\n",
    "print(f\"Reading '{filtered_merged_events_file}'...\")\n",
    "filtered_merged_events_data = pd.read_csv(filtered_merged_events_file)\n",
    "print(f\"'{filtered_merged_events_file}' loaded with {len(filtered_merged_events_data)} rows.\")\n",
    "\n",
    "# Step 2: Concatenate both DataFrames\n",
    "print(\"Concatenating the DataFrames...\")\n",
    "combined_data = pd.concat([first_100_games_data, filtered_merged_events_data], ignore_index=True)\n",
    "print(f\"Combined DataFrame has {len(combined_data)} rows.\")\n",
    "\n",
    "# Step 3: Sort the combined DataFrame by fixture_id\n",
    "print(\"Sorting the combined DataFrame by 'fixture_id'...\")\n",
    "combined_data = combined_data.sort_values(by='fixture_id').reset_index(drop=True)\n",
    "print(\"DataFrame sorted.\")\n",
    "\n",
    "# Step 4: Display the first few rows of the combined DataFrame\n",
    "print(\"Displaying the first 5 rows of the sorted DataFrame:\")\n",
    "print(combined_data.head())\n",
    "\n",
    "# Step 5: Optionally save to a new CSV\n",
    "output_file = 'combined_sorted_by_fixture_id.csv'\n",
    "print(f\"Saving the combined DataFrame to '{output_file}'...\")\n",
    "combined_data.to_csv(output_file, index=False)\n",
    "print(f\"Data saved as '{output_file}'.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 'first_100_games.csv'...\n",
      "'first_100_games.csv' loaded with 16749 rows.\n",
      "Reading 'filtered_merged_events.csv'...\n",
      "'filtered_merged_events.csv' loaded with 114772 rows.\n",
      "Concatenating the DataFrames...\n",
      "Combined DataFrame has 131521 rows.\n",
      "Sorting the combined DataFrame by 'fixture_id'...\n",
      "DataFrame sorted.\n",
      "Displaying the first 5 rows of the sorted DataFrame:\n",
      "   fixture_id event_time  team_id event_type      detailed_type  \\\n",
      "0         113         91       45       Pass    Pass_Successful   \n",
      "1         113         48       45       Pass    Pass_Successful   \n",
      "2         113         36       48       Pass  Pass_Unsuccessful   \n",
      "3         113         36       48       Pass    Pass_Successful   \n",
      "4         113         31       48       Pass    Pass_Successful   \n",
      "\n",
      "   main_player_id  secondary_player_id  \n",
      "0          2990.0                  NaN  \n",
      "1         18760.0                  NaN  \n",
      "2          2412.0                  NaN  \n",
      "3          2412.0                  NaN  \n",
      "4         18826.0                  NaN  \n",
      "Saving the combined DataFrame to 'combined_sorted_by_fixture_id.csv'...\n",
      "Data saved as 'combined_sorted_by_fixture_id.csv'.\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:29:57.557244Z",
     "start_time": "2025-01-14T09:29:57.525772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of rows in the DataFrame\n",
    "num_rows = combined_data.shape[0]\n",
    "\n",
    "# List of column names\n",
    "column_names = combined_data.columns.tolist()\n",
    "\n",
    "# Unique values in the 'event_type' column\n",
    "unique_event_types = combined_data['event_type'].unique()\n",
    "\n",
    "# Print results\n",
    "print(f\"Number of rows in the DataFrame: {num_rows}\")\n",
    "print(f\"List of column names: {column_names}\")\n",
    "print(f\"Unique values in 'event_type' column: {unique_event_types}\")\n"
   ],
   "id": "e8e469609a4faba2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the DataFrame: 131521\n",
      "List of column names: ['fixture_id', 'event_time', 'team_id', 'event_type', 'detailed_type', 'main_player_id', 'secondary_player_id']\n",
      "Unique values in 'event_type' column: ['Pass' 'BallRecovery' 'Foul' 'BallTouch' 'Interception' 'Clearance'\n",
      " 'Aerial' 'Challenge' 'Dispossessed' 'TakeOn' 'KeeperPickup' 'Goal' 'Card'\n",
      " 'subst' 'SubstitutionOff' 'OffsideGiven' 'MissedShots' 'ShotOnPost'\n",
      " 'KeeperSweeper' 'Possession' 'FormationChange' 'FormationSet' 'Error'\n",
      " 'SavedShot' 'BlockedPass' 'Save' 'CornerAwarded' 'GoodSkill'\n",
      " 'ShieldBallOpp' 'Tackle' 'OffsidePass' 'OffsideProvoked' 'SubstitutionOn'\n",
      " 'Punch' 'Claim' 'PenaltyFaced' 'Smother' 'ChanceMissed' 'CrossNotClaimed'\n",
      " 'Var']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:32:39.250302Z",
     "start_time": "2025-01-14T09:32:39.170204Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# make all the data in column event_time to be string\n",
    "# Convert all values in the \"event_time\" column to strings\n",
    "combined_data['event_time'] = combined_data['event_time'].astype(str)"
   ],
   "id": "80a74882af1dfde",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:32:46.075338Z",
     "start_time": "2025-01-14T09:32:46.016487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count the number of missing values in each column\n",
    "missing_values = combined_data.isnull().sum()\n",
    "# Filter and print only the columns with missing values greater than zero\n",
    "non_zero_missing = missing_values[missing_values > 0]\n",
    "print(non_zero_missing)\n",
    "# check how much rows in the db\n",
    "# num_rows = data.count()\n",
    "# print(num_rows)"
   ],
   "id": "cbe01d1b1673d99",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_player_id          11322\n",
      "secondary_player_id    128167\n",
      "dtype: int64\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:33:26.542435Z",
     "start_time": "2025-01-14T09:33:13.174872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check that all the main player id missing is from types which not include players\n",
    "# Create a set to store `detailed_type` values where `main_player_id` is empty\n",
    "detailed_type_set = set()\n",
    "\n",
    "# Iterate through the rows where `main_player_id` is NaN or empty\n",
    "for idx, row in combined_data.iterrows():\n",
    "    if pd.isna(row['main_player_id']) or row['main_player_id'] == '':\n",
    "        detailed_type_set.add(row['event_type'])\n",
    "\n",
    "# Display the resulting set\n",
    "print(detailed_type_set)\n",
    "\n",
    "# Filter rows where `main_player_id` is missing\n",
    "missing_main_player = combined_data[combined_data['main_player_id'].isna() | (combined_data['main_player_id'] == '')]\n",
    "\n",
    "# Count the occurrences of each `detailed_type` for missing `main_player_id`\n",
    "missing_counts = missing_main_player['event_type'].value_counts()\n",
    "\n",
    "# Print the results\n",
    "for event_type, count in missing_counts.items():\n",
    "    print(f\"Missing values for event_type '{event_type}': {count}\")\n",
    "\n",
    "\n",
    "# after check randomly - the data is missing from the api \n",
    "# FormationSet,Possession,FormationChange is ok that we have missing values - it's not related to specific player\n",
    "# card missing values we will drop\n",
    "# subst and goal - it is importat to know that the event happe, but not who did it (at least for now) we will fill the main player as generic player with id 0\n",
    "\n"
   ],
   "id": "2587884fad9cd40a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Possession', 'FormationSet', 'FormationChange'}\n",
      "Missing values for event_type 'Possession': 9772\n",
      "Missing values for event_type 'FormationChange': 1106\n",
      "Missing values for event_type 'FormationSet': 444\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:34:36.280762Z",
     "start_time": "2025-01-14T09:34:23.109063Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a copy of the original data to work on\n",
    "updated_data = combined_data.copy()\n",
    "\n",
    "# Filter rows where `main_player_id` is missing\n",
    "missing_main_player = updated_data[updated_data['main_player_id'].isna() | (updated_data['main_player_id'] == '')]\n",
    "\n",
    "# Count the missing occurrences for each `event_type`\n",
    "missing_counts = missing_main_player['event_type'].value_counts()\n",
    "print(\"Missing value counts by `event_type`:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Process the missing values based on your logic\n",
    "for idx, row in updated_data.iterrows():\n",
    "    if pd.isna(row['main_player_id']) or row['main_player_id'] == '':\n",
    "        event_type = row['event_type']\n",
    "\n",
    "        if event_type in {\"FormationSet\", \"Possession\", \"FormationChange\"}:\n",
    "            # It's okay to have missing values, so do nothing\n",
    "            continue\n",
    "\n",
    "        elif event_type == \"Card\":\n",
    "            # Drop rows with `event_type` as \"card\"\n",
    "            updated_data.drop(index=idx, inplace=True)\n",
    "\n",
    "        elif event_type in {\"subst\", \"Goal\"}:\n",
    "            # Replace missing `main_player_id` with a generic player ID (0)\n",
    "            updated_data.at[idx, 'main_player_id'] = 0\n",
    "\n",
    "# Reset the index of the updated DataFrame after dropping rows\n",
    "updated_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Verify the results\n",
    "print(\"Processing complete. Updated DataFrame:\")\n",
    "print(updated_data.head())\n",
    "\n",
    "# Filter rows where `main_player_id` is missing\n",
    "missing_main_player = updated_data[updated_data['main_player_id'].isna() | (updated_data['main_player_id'] == '')]\n",
    "\n",
    "# Count the missing occurrences for each `event_type`\n",
    "missing_counts = missing_main_player['event_type'].value_counts()\n",
    "print(\"Missing main player value counts by `event_type`:\")\n",
    "print(missing_counts)\n"
   ],
   "id": "6ce62d6642b4fcaf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing value counts by `event_type`:\n",
      "event_type\n",
      "Possession         9772\n",
      "FormationChange    1106\n",
      "FormationSet        444\n",
      "Name: count, dtype: int64\n",
      "Processing complete. Updated DataFrame:\n",
      "   fixture_id event_time  team_id event_type      detailed_type  \\\n",
      "0         113         91       45       Pass    Pass_Successful   \n",
      "1         113         48       45       Pass    Pass_Successful   \n",
      "2         113         36       48       Pass  Pass_Unsuccessful   \n",
      "3         113         36       48       Pass    Pass_Successful   \n",
      "4         113         31       48       Pass    Pass_Successful   \n",
      "\n",
      "   main_player_id  secondary_player_id  \n",
      "0          2990.0                  NaN  \n",
      "1         18760.0                  NaN  \n",
      "2          2412.0                  NaN  \n",
      "3          2412.0                  NaN  \n",
      "4         18826.0                  NaN  \n",
      "Missing main player value counts by `event_type`:\n",
      "event_type\n",
      "Possession         9772\n",
      "FormationChange    1106\n",
      "FormationSet        444\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:34:55.020826Z",
     "start_time": "2025-01-14T09:34:54.890918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to process the `event_time` column\n",
    "def process_event_time(value):\n",
    "    try:\n",
    "        if value.isdigit():\n",
    "            # If the value is a number as a string, convert it to an integer\n",
    "            return int(value)\n",
    "        # Check if the value is a negative number as a string\n",
    "        elif value.lstrip('-').isdigit():\n",
    "            return int(value)\n",
    "        elif '+' in value:\n",
    "            base, extra = value.split('+')\n",
    "            if base == \"90\":\n",
    "                # For \"90+something\", return the integer sum\n",
    "                return int(base) + int(extra)\n",
    "            elif base == \"45\":\n",
    "                # For \"45+something\", return a float \"45.something\"\n",
    "                return float(f\"{base}.{extra}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected format: {value}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing value '{value}': {e}\")\n",
    "        return None  # Return None for invalid cases\n",
    "\n",
    "# Apply the function to the `event_time` column in the updated_data DataFrame\n",
    "updated_data['event_time'] = updated_data['event_time'].apply(process_event_time)\n",
    "\n",
    "# Verify the results\n",
    "print(\"Processed DataFrame (updated_data):\")\n",
    "print(updated_data.head())\n",
    "\n",
    "\n",
    "# Count the number of non-integer values in the event_time column\n",
    "non_float_count = updated_data['event_time'].apply(lambda x: not isinstance(x, float)).sum()\n",
    "\n",
    "print(f\"Number of non-float values in the 'event_time' column: {non_float_count}\")\n",
    "\n"
   ],
   "id": "debad72037142beb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed DataFrame (updated_data):\n",
      "   fixture_id  event_time  team_id event_type      detailed_type  \\\n",
      "0         113        91.0       45       Pass    Pass_Successful   \n",
      "1         113        48.0       45       Pass    Pass_Successful   \n",
      "2         113        36.0       48       Pass  Pass_Unsuccessful   \n",
      "3         113        36.0       48       Pass    Pass_Successful   \n",
      "4         113        31.0       48       Pass    Pass_Successful   \n",
      "\n",
      "   main_player_id  secondary_player_id  \n",
      "0          2990.0                  NaN  \n",
      "1         18760.0                  NaN  \n",
      "2          2412.0                  NaN  \n",
      "3          2412.0                  NaN  \n",
      "4         18826.0                  NaN  \n",
      "Number of non-float values in the 'event_time' column: 0\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:35:42.273336Z",
     "start_time": "2025-01-14T09:35:21.267841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dictionary to store counts of event types with `event_time < 0`\n",
    "negative_event_time_dict = {}\n",
    "\n",
    "# Iterate over rows where `event_time` is less than 0\n",
    "for idx, row in updated_data.iterrows():\n",
    "    if row['event_time'] < 0:\n",
    "        event_type = row['event_type']\n",
    "        # Increment the count for the event type in the dictionary\n",
    "        if event_type in negative_event_time_dict:\n",
    "            negative_event_time_dict[event_type] += 1\n",
    "        else:\n",
    "            negative_event_time_dict[event_type] = 1\n",
    "\n",
    "# Print the dictionary\n",
    "print(negative_event_time_dict)\n",
    "print(\"Counts of rows with `event_time < 0` by `event_type`:\")\n",
    "for event_type, count in negative_event_time_dict.items():\n",
    "    print(f\"{event_type}: {count}\")\n",
    "\n",
    "\n",
    "# we will drop the rows if the type is card else we will check based on the number of problematic values\n",
    "# Count the number of rows that match the condition\n",
    "rows_to_delete = updated_data[(updated_data['event_time'] < 0) & (updated_data['event_type'] == \"Card\")].shape[0]\n",
    "\n",
    "# Drop rows where `event_time` < 0 and `event_type` is \"Card\"\n",
    "updated_data = updated_data[~((updated_data['event_time'] < 0) & (updated_data['event_type'] == \"Card\"))]\n",
    "\n",
    "# Reset the index of the DataFrame after dropping rows\n",
    "updated_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the number of rows deleted\n",
    "print(f\"Number of rows deleted: {rows_to_delete}\")\n",
    "\n",
    "# check if it indeed delete\n",
    "# Create a dictionary to store counts of event types with `event_time < 0`\n",
    "negative_event_time_dict = {}\n",
    "\n",
    "# Iterate over rows where `event_time` is less than 0\n",
    "for idx, row in updated_data.iterrows():\n",
    "    if row['event_time'] < 0:\n",
    "        event_type = row['event_type']\n",
    "        # Increment the count for the event type in the dictionary\n",
    "        if event_type in negative_event_time_dict:\n",
    "            negative_event_time_dict[event_type] += 1\n",
    "        else:\n",
    "            negative_event_time_dict[event_type] = 1\n",
    "\n",
    "# Print the dictionary\n",
    "print(negative_event_time_dict)\n",
    "print(\"Counts of rows with `event_time < 0` by `event_type`:\")\n",
    "for event_type, count in negative_event_time_dict.items():\n",
    "    print(f\"{event_type}: {count}\")"
   ],
   "id": "db71a882b9d266dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Card': 1}\n",
      "Counts of rows with `event_time < 0` by `event_type`:\n",
      "Card: 1\n",
      "Number of rows deleted: 1\n",
      "{}\n",
      "Counts of rows with `event_time < 0` by `event_type`:\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:36:12.244774Z",
     "start_time": "2025-01-14T09:36:12.218932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# every missing secondary player we will fill with the \"default\" player - 0\n",
    "# Fill NaN values in the 'secondary_player' column with 0\n",
    "updated_data['secondary_player_id'] = updated_data['secondary_player_id'].fillna(0)\n",
    "\n",
    "# Verify the changes\n",
    "print(\"Updated DataFrame with 'secondary_player_id' NaN values filled:\")\n",
    "print(updated_data.head())"
   ],
   "id": "b83c5797f11d003d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with 'secondary_player_id' NaN values filled:\n",
      "   fixture_id  event_time  team_id event_type      detailed_type  \\\n",
      "0         113        91.0       45       Pass    Pass_Successful   \n",
      "1         113        48.0       45       Pass    Pass_Successful   \n",
      "2         113        36.0       48       Pass  Pass_Unsuccessful   \n",
      "3         113        36.0       48       Pass    Pass_Successful   \n",
      "4         113        31.0       48       Pass    Pass_Successful   \n",
      "\n",
      "   main_player_id  secondary_player_id  \n",
      "0          2990.0                  0.0  \n",
      "1         18760.0                  0.0  \n",
      "2          2412.0                  0.0  \n",
      "3          2412.0                  0.0  \n",
      "4         18826.0                  0.0  \n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:37:49.959225Z",
     "start_time": "2025-01-14T09:37:49.849868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Sort the DataFrame by fixture_id and event_time\n",
    "print(\"Sorting the DataFrame by 'fixture_id' and 'event_time'\")\n",
    "updated_data = updated_data.sort_values(by=['fixture_id', 'event_time']).reset_index(drop=True)\n",
    "print(\"DataFrame sorted.\")\n",
    "\n",
    "# Step 2: Display the first 5 rows of the sorted DataFrame\n",
    "print(\"Displaying the first 5 rows of the sorted DataFrame:\")\n",
    "print(updated_data.head())\n",
    "\n"
   ],
   "id": "68895b77c1f4445f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting the DataFrame by 'fixture_id' and 'event_time'\n",
      "DataFrame sorted.\n",
      "Displaying the first 5 rows of the sorted DataFrame:\n",
      "   fixture_id  event_time  team_id    event_type    detailed_type  \\\n",
      "0         113         0.0       48  FormationSet          4-1-4-1   \n",
      "1         113         0.0       48  FormationSet          4-1-4-1   \n",
      "2         113         0.0       45          Pass  Pass_Successful   \n",
      "3         113         0.0       45          Pass  Pass_Successful   \n",
      "4         113         0.0       48  FormationSet          4-1-4-1   \n",
      "\n",
      "   main_player_id  secondary_player_id  \n",
      "0             NaN                  0.0  \n",
      "1             NaN                  0.0  \n",
      "2          2990.0                  0.0  \n",
      "3         18764.0                  0.0  \n",
      "4             NaN                  0.0  \n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:39:05.596753Z",
     "start_time": "2025-01-14T09:39:05.532877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Count the number of duplicate rows\n",
    "duplicate_count = updated_data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows in the DataFrame: {duplicate_count}\")"
   ],
   "id": "e02d5845e6745d29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows in the DataFrame: 31739\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:39:36.505272Z",
     "start_time": "2025-01-14T09:39:36.444557Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 3: Remove duplicate rows\n",
    "print(f\"Number of rows before removing duplicates: {len(updated_data)}\")\n",
    "updated_data = updated_data.drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Number of rows after removing duplicates: {len(updated_data)}\")\n"
   ],
   "id": "b2f89867288c06b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before removing duplicates: 131520\n",
      "Number of rows after removing duplicates: 99781\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:40:27.293766Z",
     "start_time": "2025-01-14T09:40:26.030049Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Step 1: Create a new column for possession_detailed_type\n",
    "updated_data['possession_detailed_type'] = updated_data.apply(\n",
    "    lambda row: row['detailed_type'] if row['event_type'] == 'Possession' else 0, axis=1\n",
    ")\n",
    "\n",
    "# Step 2: Update the `detailed_type` column to 0 where `event_type` is `Possession`\n",
    "updated_data['detailed_type'] = updated_data.apply(\n",
    "    lambda row: 0 if row['event_type'] == 'Possession' else row['detailed_type'], axis=1\n",
    ")\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(updated_data.head())"
   ],
   "id": "41798c85fd96fdf4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixture_id  event_time  team_id    event_type         detailed_type  \\\n",
      "0         113         0.0       48  FormationSet               4-1-4-1   \n",
      "1         113         0.0       45          Pass       Pass_Successful   \n",
      "2         113         0.0       45          Pass       Pass_Successful   \n",
      "3         113         0.0       45        Aerial   Aerial_Unsuccessful   \n",
      "4         113         0.0       48     BallTouch  BallTouch_Successful   \n",
      "\n",
      "   main_player_id  secondary_player_id possession_detailed_type  \n",
      "0             NaN                  0.0                        0  \n",
      "1          2990.0                  0.0                        0  \n",
      "2         18764.0                  0.0                        0  \n",
      "3         18766.0                  0.0                        0  \n",
      "4         18818.0                  0.0                        0  \n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:41:26.469561Z",
     "start_time": "2025-01-14T09:41:26.394150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# do one hot encoding to the event type columns\n",
    "# Step 1: Perform One-Hot Encoding on the `event_type` column\n",
    "event_type_encoded = pd.get_dummies(updated_data['event_type'], prefix='event_type')\n",
    "# Step 2: Merge the one-hot encoded columns back to the original DataFrame\n",
    "updated_data = pd.concat([updated_data, event_type_encoded], axis=1)\n",
    "updated_data.drop(columns=['event_type'], inplace=True)\n",
    "# convert in into int and not true/false\n",
    "dummy_cols = [col for col in updated_data.columns if any(prefix in col for prefix in ['event_type_'])]\n",
    "updated_data[dummy_cols] = updated_data[dummy_cols].astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(updated_data.head())"
   ],
   "id": "3259bd903415f446",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixture_id  event_time  team_id         detailed_type  main_player_id  \\\n",
      "0         113         0.0       48               4-1-4-1             NaN   \n",
      "1         113         0.0       45       Pass_Successful          2990.0   \n",
      "2         113         0.0       45       Pass_Successful         18764.0   \n",
      "3         113         0.0       45   Aerial_Unsuccessful         18766.0   \n",
      "4         113         0.0       48  BallTouch_Successful         18818.0   \n",
      "\n",
      "   secondary_player_id possession_detailed_type  event_type_Aerial  \\\n",
      "0                  0.0                        0                  0   \n",
      "1                  0.0                        0                  0   \n",
      "2                  0.0                        0                  0   \n",
      "3                  0.0                        0                  1   \n",
      "4                  0.0                        0                  0   \n",
      "\n",
      "   event_type_BallRecovery  event_type_BallTouch  ...  event_type_SavedShot  \\\n",
      "0                        0                     0  ...                     0   \n",
      "1                        0                     0  ...                     0   \n",
      "2                        0                     0  ...                     0   \n",
      "3                        0                     0  ...                     0   \n",
      "4                        0                     1  ...                     0   \n",
      "\n",
      "   event_type_ShieldBallOpp  event_type_ShotOnPost  event_type_Smother  \\\n",
      "0                         0                      0                   0   \n",
      "1                         0                      0                   0   \n",
      "2                         0                      0                   0   \n",
      "3                         0                      0                   0   \n",
      "4                         0                      0                   0   \n",
      "\n",
      "   event_type_SubstitutionOff  event_type_SubstitutionOn  event_type_Tackle  \\\n",
      "0                           0                          0                  0   \n",
      "1                           0                          0                  0   \n",
      "2                           0                          0                  0   \n",
      "3                           0                          0                  0   \n",
      "4                           0                          0                  0   \n",
      "\n",
      "   event_type_TakeOn  event_type_Var  event_type_subst  \n",
      "0                  0               0                 0  \n",
      "1                  0               0                 0  \n",
      "2                  0               0                 0  \n",
      "3                  0               0                 0  \n",
      "4                  0               0                 0  \n",
      "\n",
      "[5 rows x 47 columns]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:42:57.931536Z",
     "start_time": "2025-01-14T09:42:57.784528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# do one hot encoding to the event type columns\n",
    "# Step 1: Perform One-Hot Encoding on the `event_type` column\n",
    "detailed_type_encoded = pd.get_dummies(updated_data['detailed_type'], prefix='detailed_type')\n",
    "# Step 2: Merge the one-hot encoded columns back to the original DataFrame\n",
    "updated_data = pd.concat([updated_data, detailed_type_encoded], axis=1)\n",
    "updated_data.drop(columns=['detailed_type'], inplace=True)\n",
    "# convert in into int and not true/false\n",
    "dummy_cols = [col for col in updated_data.columns if any(prefix in col for prefix in ['detailed_type_'])]\n",
    "updated_data[dummy_cols] = updated_data[dummy_cols].astype(int)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(updated_data.head())"
   ],
   "id": "ee498633a363d05e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixture_id  event_time  team_id  main_player_id  secondary_player_id  \\\n",
      "0         113         0.0       48             NaN                  0.0   \n",
      "1         113         0.0       45          2990.0                  0.0   \n",
      "2         113         0.0       45         18764.0                  0.0   \n",
      "3         113         0.0       45         18766.0                  0.0   \n",
      "4         113         0.0       48         18818.0                  0.0   \n",
      "\n",
      "  possession_detailed_type  event_type_Aerial  event_type_BallRecovery  \\\n",
      "0                        0                  0                        0   \n",
      "1                        0                  0                        0   \n",
      "2                        0                  0                        0   \n",
      "3                        0                  1                        0   \n",
      "4                        0                  0                        0   \n",
      "\n",
      "   event_type_BallTouch  event_type_BlockedPass  ...  \\\n",
      "0                     0                       0  ...   \n",
      "1                     0                       0  ...   \n",
      "2                     0                       0  ...   \n",
      "3                     0                       0  ...   \n",
      "4                     1                       0  ...   \n",
      "\n",
      "   detailed_type_Substitution 3  detailed_type_Substitution 4  \\\n",
      "0                             0                             0   \n",
      "1                             0                             0   \n",
      "2                             0                             0   \n",
      "3                             0                             0   \n",
      "4                             0                             0   \n",
      "\n",
      "   detailed_type_Substitution 5  detailed_type_SubstitutionOff_Successful  \\\n",
      "0                             0                                         0   \n",
      "1                             0                                         0   \n",
      "2                             0                                         0   \n",
      "3                             0                                         0   \n",
      "4                             0                                         0   \n",
      "\n",
      "   detailed_type_SubstitutionOn_Successful  detailed_type_Tackle_Successful  \\\n",
      "0                                        0                                0   \n",
      "1                                        0                                0   \n",
      "2                                        0                                0   \n",
      "3                                        0                                0   \n",
      "4                                        0                                0   \n",
      "\n",
      "   detailed_type_Tackle_Unsuccessful  detailed_type_TakeOn_Successful  \\\n",
      "0                                  0                                0   \n",
      "1                                  0                                0   \n",
      "2                                  0                                0   \n",
      "3                                  0                                0   \n",
      "4                                  0                                0   \n",
      "\n",
      "   detailed_type_TakeOn_Unsuccessful  detailed_type_Yellow Card  \n",
      "0                                  0                          0  \n",
      "1                                  0                          0  \n",
      "2                                  0                          0  \n",
      "3                                  0                          0  \n",
      "4                                  0                          0  \n",
      "\n",
      "[5 rows x 125 columns]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:43:11.539048Z",
     "start_time": "2025-01-14T09:43:11.525314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify columns with non-numeric values\n",
    "non_numeric_columns = []\n",
    "\n",
    "for col in updated_data.columns:\n",
    "    if not pd.api.types.is_numeric_dtype(updated_data[col]):\n",
    "        non_numeric_columns.append(col)\n",
    "\n",
    "# Print the columns with non-numeric values\n",
    "print(\"Columns with non-numeric values:\")\n",
    "for col in non_numeric_columns:\n",
    "    print(col)\n"
   ],
   "id": "50e8861cf25639ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with non-numeric values:\n",
      "possession_detailed_type\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:43:20.283875Z",
     "start_time": "2025-01-14T09:43:20.259397Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Identify and print non-numeric values in the `possession_detailed_type` column\n",
    "non_numeric_values = updated_data['possession_detailed_type'][~updated_data['possession_detailed_type'].apply(lambda x: isinstance(x, (int, float)))]\n",
    "\n",
    "print(\"Non-numeric values in `possession_detailed_type` column:\")\n",
    "print(non_numeric_values)\n"
   ],
   "id": "bac4a213ce849e70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in `possession_detailed_type` column:\n",
      "140      57.1\n",
      "141      42.9\n",
      "253      56.0\n",
      "254      44.0\n",
      "396      56.5\n",
      "         ... \n",
      "99653    69.7\n",
      "99767    28.0\n",
      "99769    72.0\n",
      "99779    72.0\n",
      "99780    28.0\n",
      "Name: possession_detailed_type, Length: 2202, dtype: object\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:43:48.178885Z",
     "start_time": "2025-01-14T09:43:48.137236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to convert values to float\n",
    "def to_float(value):\n",
    "    try:\n",
    "        # Attempt to convert the value to float\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        # Handle non-numeric values gracefully\n",
    "        return None  # Or you can set a default value like 0.0\n",
    "\n",
    "# Apply the function to the `possession_detailed_type` column\n",
    "updated_data['possession_detailed_type'] = updated_data['possession_detailed_type'].apply(to_float)\n",
    "\n",
    "# Print the updated column to verify\n",
    "print(\"Updated `possession_detailed_type` column:\")\n",
    "print(updated_data['possession_detailed_type'])\n"
   ],
   "id": "a2619f85bd6fdfe4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated `possession_detailed_type` column:\n",
      "0         0.0\n",
      "1         0.0\n",
      "2         0.0\n",
      "3         0.0\n",
      "4         0.0\n",
      "         ... \n",
      "99776     0.0\n",
      "99777     0.0\n",
      "99778     0.0\n",
      "99779    72.0\n",
      "99780    28.0\n",
      "Name: possession_detailed_type, Length: 99781, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:43:54.636571Z",
     "start_time": "2025-01-14T09:43:54.627185Z"
    }
   },
   "cell_type": "code",
   "source": "print(updated_data.columns.to_list())",
   "id": "12813f7459fe55f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixture_id', 'event_time', 'team_id', 'main_player_id', 'secondary_player_id', 'possession_detailed_type', 'event_type_Aerial', 'event_type_BallRecovery', 'event_type_BallTouch', 'event_type_BlockedPass', 'event_type_Card', 'event_type_Challenge', 'event_type_ChanceMissed', 'event_type_Claim', 'event_type_Clearance', 'event_type_CornerAwarded', 'event_type_CrossNotClaimed', 'event_type_Dispossessed', 'event_type_Error', 'event_type_FormationChange', 'event_type_FormationSet', 'event_type_Foul', 'event_type_Goal', 'event_type_GoodSkill', 'event_type_Interception', 'event_type_KeeperPickup', 'event_type_KeeperSweeper', 'event_type_MissedShots', 'event_type_OffsideGiven', 'event_type_OffsidePass', 'event_type_OffsideProvoked', 'event_type_Pass', 'event_type_PenaltyFaced', 'event_type_Possession', 'event_type_Punch', 'event_type_Save', 'event_type_SavedShot', 'event_type_ShieldBallOpp', 'event_type_ShotOnPost', 'event_type_Smother', 'event_type_SubstitutionOff', 'event_type_SubstitutionOn', 'event_type_Tackle', 'event_type_TakeOn', 'event_type_Var', 'event_type_subst', 'detailed_type_0', 'detailed_type_18', 'detailed_type_19', 'detailed_type_21', 'detailed_type_24', 'detailed_type_3', 'detailed_type_3-4-2-1', 'detailed_type_3-4-3', 'detailed_type_3-5-1-1', 'detailed_type_3-5-2', 'detailed_type_4-1-4-1', 'detailed_type_4-2-2-2', 'detailed_type_4-2-3-1', 'detailed_type_4-3-1-2', 'detailed_type_4-3-3', 'detailed_type_4-4-1-1', 'detailed_type_4-4-2', 'detailed_type_5', 'detailed_type_5-3-2', 'detailed_type_5-4-1', 'detailed_type_9', 'detailed_type_Aerial_Successful', 'detailed_type_Aerial_Unsuccessful', 'detailed_type_BallRecovery_Successful', 'detailed_type_BallTouch_Successful', 'detailed_type_BallTouch_Unsuccessful', 'detailed_type_BlockedPass_Successful', 'detailed_type_Card_Successful', 'detailed_type_Challenge_Unsuccessful', 'detailed_type_ChanceMissed_Unsuccessful', 'detailed_type_Claim_Successful', 'detailed_type_Claim_Unsuccessful', 'detailed_type_Clearance_Successful', 'detailed_type_Clearance_Unsuccessful', 'detailed_type_CornerAwarded_Successful', 'detailed_type_CornerAwarded_Unsuccessful', 'detailed_type_CrossNotClaimed_Successful', 'detailed_type_Dispossessed_Successful', 'detailed_type_Error_Successful', 'detailed_type_Foul_Successful', 'detailed_type_Foul_Unsuccessful', 'detailed_type_Goal cancelled', 'detailed_type_Goal_Successful', 'detailed_type_GoodSkill_Successful', 'detailed_type_Interception_Successful', 'detailed_type_KeeperPickup_Successful', 'detailed_type_KeeperSweeper_Successful', 'detailed_type_KeeperSweeper_Unsuccessful', 'detailed_type_MissedShots_Successful', 'detailed_type_Normal Goal', 'detailed_type_OffsideGiven_Unsuccessful', 'detailed_type_OffsidePass_Successful', 'detailed_type_OffsideProvoked_Successful', 'detailed_type_Own Goal', 'detailed_type_Pass_Successful', 'detailed_type_Pass_Unsuccessful', 'detailed_type_Penalty', 'detailed_type_Penalty awarded', 'detailed_type_Penalty cancelled', 'detailed_type_PenaltyFaced_Unsuccessful', 'detailed_type_Punch_Successful', 'detailed_type_Red Card', 'detailed_type_Save_Successful', 'detailed_type_SavedShot_Successful', 'detailed_type_ShieldBallOpp_Successful', 'detailed_type_ShotOnPost_Successful', 'detailed_type_Smother_Successful', 'detailed_type_Substitution 1', 'detailed_type_Substitution 2', 'detailed_type_Substitution 3', 'detailed_type_Substitution 4', 'detailed_type_Substitution 5', 'detailed_type_SubstitutionOff_Successful', 'detailed_type_SubstitutionOn_Successful', 'detailed_type_Tackle_Successful', 'detailed_type_Tackle_Unsuccessful', 'detailed_type_TakeOn_Successful', 'detailed_type_TakeOn_Unsuccessful', 'detailed_type_Yellow Card']\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T09:58:08.609292Z",
     "start_time": "2025-01-14T09:58:08.505946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Columns to drop and check for values\n",
    "columns_to_drop = [\n",
    "    'event_type_BallTouch', 'event_type_Error', 'event_type_GoodSkill',\n",
    "    'event_type_Punch', 'event_type_Save', 'event_type_SubstitutionOff', 'event_type_SubstitutionOn'\n",
    "]\n",
    "\n",
    "# Step 1: Remove rows where any of the specified columns have a value of 1\n",
    "print(f\"Number of rows before filtering: {len(updated_data)}\")\n",
    "updated_data = updated_data[~updated_data[columns_to_drop].eq(1).any(axis=1)]\n",
    "print(f\"Number of rows after removing rows with value 1 in specified columns: {len(updated_data)}\")\n",
    "\n",
    "# Step 2: Drop the specified columns\n",
    "updated_data = updated_data.drop(columns=columns_to_drop)\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n"
   ],
   "id": "62f1a257860bcfaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering: 99781\n",
      "Number of rows after removing rows with value 1 in specified columns: 94549\n",
      "Dropped columns: ['event_type_BallTouch', 'event_type_Error', 'event_type_GoodSkill', 'event_type_Punch', 'event_type_Save', 'event_type_SubstitutionOff', 'event_type_SubstitutionOn']\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:02:43.729235Z",
     "start_time": "2025-01-14T10:02:43.630232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Columns to drop and check for values\n",
    "columns_to_drop = [\n",
    "    'detailed_type_BallTouch_Successful', 'detailed_type_BallTouch_Unsuccessful',\n",
    "    'detailed_type_Error_Successful', 'detailed_type_GoodSkill_Successful',\n",
    "    'detailed_type_Save_Successful', 'detailed_type_SubstitutionOff_Successful',\n",
    "    'detailed_type_SubstitutionOn_Successful'\n",
    "]\n",
    "\n",
    "# Step 1: Remove rows where any of the specified columns have a value of 1\n",
    "print(f\"Number of rows before filtering: {len(updated_data)}\")\n",
    "updated_data = updated_data[~updated_data[columns_to_drop].eq(1).any(axis=1)]\n",
    "print(f\"Number of rows after removing rows with value 1 in specified columns: {len(updated_data)}\")\n",
    "\n",
    "# Step 2: Drop the specified columns\n",
    "updated_data = updated_data.drop(columns=columns_to_drop)\n",
    "print(f\"Dropped columns: {columns_to_drop}\")\n",
    "\n",
    "# Count the number of columns\n",
    "num_columns = len(updated_data.columns)\n",
    "print(f\"Number of columns in the DataFrame: {num_columns}\")\n"
   ],
   "id": "4ac48be92f956888",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before filtering: 94549\n",
      "Number of rows after removing rows with value 1 in specified columns: 94549\n",
      "Dropped columns: ['detailed_type_BallTouch_Successful', 'detailed_type_BallTouch_Unsuccessful', 'detailed_type_Error_Successful', 'detailed_type_GoodSkill_Successful', 'detailed_type_Save_Successful', 'detailed_type_SubstitutionOff_Successful', 'detailed_type_SubstitutionOn_Successful']\n",
      "Number of columns in the DataFrame: 111\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-14T10:04:11.370381Z",
     "start_time": "2025-01-14T10:04:09.943072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the cleaned DataFrame\n",
    "output_file = '100_games_events_table.csv'\n",
    "updated_data.to_csv(output_file, index=False)\n",
    "print(f\"Cleaned DataFrame saved as '{output_file}'.\")"
   ],
   "id": "af6293b67431485d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame saved as '100_games_events_table.csv'.\n"
     ]
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
